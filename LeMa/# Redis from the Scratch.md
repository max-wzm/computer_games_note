# Redis from the Scratch

## 数据结构

本节主要包含两部分：

- 数据结构基础：类型与实现、存储方式
- 应用案例：不同场景需要使用哪些数据结构解决？

### 键值存储

Redis 是一个 KV数据库，因此一个 KV pair 是存储在 **哈希表** 当中的。

（todo：哈希表专题）

在哈希表当中不可避免地存在 **哈希碰撞** 的问题，发生碰撞的所有 KV pair 构成了一个哈希桶（或者说，哈希表的一项）。解决哈希碰撞有很多方法（有哪些？），Redis 当中采用了 **链式哈希** ，也就是说，发生碰撞的所有 KV pair 通过链表连接。

在查找时，通过 Hash(key) 找到对应的哈希桶，在桶内有一个链表，遍历此链表即可找到 key 对应的 pair(或者叫entry)。

由此我们可以定义一个 entry 的 **存储结构** ：

- *key: 指向key RedisObject的指针，8B
- *value： 指向val RedisObject的指针，8B
- *next：指向链表的下一结点。

> RedisObject={metadata: 8B, ptr: 8B}

链表的查找是O(n)的，因此我们引出了另一个问题：如何在发生频繁碰撞时进行 **扩容** ？

Redis 使用了 渐进式 rehash：全局有两个哈希表，表1作为主表。需要扩容时：

- 先给表2分配更大的空间
- 每次处理一个请求时，把主表的一个桶 rehash 到备表
- 释放主表对应的空间

在查找时，先查主表，如果主表没有key，再查备表。

在 rehash 的过程当中会涉及到大量数据拷贝，一次性复制会堵塞主线程。采用渐进式 rehash 可以将数据拷贝的时间消耗分散到每个请求当中。

### Value 数据类型

Redis 当中的 key 类型为 string，而 value 的类型则多种多样。

Redis 抽象出了五种基本的 value 类型：

1. String：字符串，包括数字
2. List：顺序列表
3. Hash：哈希表
4. Set：集合
5. Sorted Set：有序集合，即每个元素都有权重。

### 底层类型实现

Redis 提供的5种基本数据结构是通过6种底层结构实现的。

- 数组
- 双向链表
- 哈希表
- 跳表：
  跳表是在原有的数组上不断添加一层层的索引实现的。从底层的数据开始，每一层都基于底下一层进行一个步长为2的leap，形成一个类似于B+树的结构。
  因此，跳表的查找是O(logn)的。
- 压缩列表：
  压缩列表类似于数组，但是多了zlbytes, zltail, zllen, zlend四个字段。
- 动态字符串：
  相比于C的字符串（char数组），动态字符串包括了以下三个字段：
  - buf：字符数组
  - len 4B：字符串的实际长度
  - alloc 4B：分配给buf的长度，通常大于len

### 数据存储 - 如何设计更节约空间的KV对？

考虑一个 Long - Long 的KV对，理想的占用空间为16B.

如果val用String存储需要消耗多少的空间？

> 对于一个key和val，存储在一个RedisObject={metadata: 8B, ptr: 8B}当中。如果key和val是整数，ptr可以优化为直接赋值。因此各自有16B。
> 对于一个entry的结构, 需要8+8+8=24B。由于Redis的内存分配策略，实际分配2的n次，即32B。
> 总计64B。

可以看到，有75%的空间占用的无效的。

如何优化呢，我们发现一个 entry 至少占用了 64B：

1. key, value 中RedisObject 的开销
2. entry 本身的开销 

尽可能节约空间要求我们少用 entry。因此可以考虑：把多个 kv pair 聚合到一个 entry 当中。

也就是说，一个 entry 存放一个哈希表，kv pair放在哈希表里面。

例如，以key-id后三位作路由，将所有的 kv pair 分散到1000个entry当中。就可以省去大部分RedisObject和entry的消耗了。

### 统计方法 - 不同的统计方法应该使用哪些数据结构？

1. 聚合统计：交、并、差
   使用Set。
   注意，交并差的复杂度很高，容易阻塞redis进程。因此更建议放到客户端去处理，或者交给从服务器。
2. 排序统计：
   Redis 结构当中，List和Sorted Set是有序集合。
   List按照进入顺序排序，最新的元素在队头。
   Sorted Set按照自定义的权值排序。
3. 二元状态统计：
   使用Bitmap。整体类似于boolean[]。底层是通过String来实现的。
4. 基数统计：统计集合中元素的个数
   除了使用Set和哈希表（both space-consuming）之外，还可以用HyperLogLog.
   HLL 有非常复杂的数学原理，但是他可以通过固定的空间（12KB）来统最多2^64个元素。
   但是HLL的计数是基于概率的，因此会有约0.81%的误差。

### 时间序列 - 如何存储？

时间序列的三个任务：

- 点查询
- 范围查询
- 聚合计算

实现：

1. Zset & HashTable
   时间序列的存储通常是带有时间戳的。首先可以考虑用Zset存储，以timestamp作为权重。好处是支持范围查询。
   单点查询的效率是O(logn), 如果想再优化，可以再加上一个哈希表。
   为了保证Zset和HashTable的一致性，需要使用Redis当中的事务，如multi - exec。
   这样做的好处是使用的都是 Redis 原生的基础结构，可控、稳定，且性能经过充分的优化。
   坏处是：
   1. 没有提供专门的聚合计算的api。
   2. 时间序列会产生大量的数据，通过网络传输给Client会影响网络环境。
   3. Zset自带去重，因此新元素会把旧元素覆盖。
2. 使用RedisTimeSeries模块
   通过链接上去使用。
   好处：提供了一系列api、不需要客户端处理、内存占用少
   坏处：速度慢，底层用链表O(n), 点查询只能查latest，范围查询O(n).

### 消息队列 - Redis 可以做消息队列吗？

消息队列需要实现的三个特性：

- 有序性：FIFO
- 幂等性：重复消息
- 可靠性：不遗失

Redis 本身提供了一些数据结构和api，可以实现轻量级的消息队列。

#### 基于List的实现方案

List本身是有序的，实现了有序性。

对于幂等性，需要由producer为每个消息生成一个id，放到列队当中。consumer取出时，需要维护其取出的msg id集合。从而避免了重复消费某一消息。

而对于可靠性，Redis 提供了 `BRPOPLPUSH` 命令，此命令取出消息时，消息可以进入另一个mqback队列。此时consumer宕机之后，可以从mqback队列当中读取未处理完的消息。

> mqback寄了怎么办？这是Redis自己的可靠性问题了，如AOF、RDB来解决。

#### 基于Streams的实现方案

Streams是 Redis 为消息队列定制数据结构。相比于List，他支持消费组。也就是说同个消息可以派发个多个消费组。

对于幂等性而言，ID是Streams自动生成的，用户无需再关注。

对于可靠性，Streams采用了pending list, 收存已读取的消息。consumer完成消费之后，发送ACK确认。

Streams可以看成是对List实现消息队列方案的一个封装。

### 进阶数据结构总结

#### HyperLogLog 

#### Bitmap

#### GEO 

#### Streams

#### Bloom Filter

前面我们介绍过 HyperLogLog 作为 Set 在计数问题的一种补充。

Bloom Filter 则是 Set 在包含/不包含问题的补充。BF 可以回答一个元素 在不在 集合内的问题。

BF 包括了一个 Bitmap 与若干个哈希函数。 

- 对于一个元素的加入，若干个哈希函数得到若干输出，将对应位的 Bitmap 置1.
- 对于查看一个元素是否在集合内，检验对应位的 Bitmap 是否为1即可。

例如，选取8位的 Bitmap，2个哈希函数。元素 e1 加入时，hash1(e1) = 4, hash2(e1) = 5. 则将 Bitmap 的4，5位置1。同理 e2 加入时，hash一波，得到将 Bitmap 的5，6位置1. 查询是否存在时，对于元素 e1，查询 Bitmap 的4，5位是否都是1即可。

BF 非常节省内存，只受 Bitmap 大小约束，而与元素个数无关。但是以上的过程也暴露出 BF 的两个缺点：

1. 哈希碰撞。假如有一个 e3 的哈希结果是4，6. 由于与 e1，e2 发生了哈希碰撞，即使 e3 不在 BF 当中，我们也能得到 Bitmap 的4，6位为1，返回错误的结果。因此，BF只能给出 **not contain / might contain** 的结果，无法结出确定 contain 的结论。可以增加hash函数，和 Bitmap 空间。
2. 不便删除。也是由于哈希碰撞的原因，几个元素共用一个 bit 位，此时删除就不太方便了，会影响到其他元素。可以把 bit 变成 int 计数来解决。

挖个坑，BF 还有很有升级版，有空总结。

#### 自定义结构

## 线程模型

### 基本单线程

Redis 是单线程的吗？

Yes, and No.

我们说 Redis 是单线程的，指的是 Redis 的主要服务，如网络IO以及KV数据操作是在一个线程之内完成的。

而 Redis 在实际上还有其他线程在工作，主要负责以下功能：持久化、异步删除、集群同步。

因此我们说，Redis **基本上** 是单线程的。

为什么 Redis 不积极拥抱并发呢？简单来说，CPU 并不是制约 Redis 性能的主要因素。这是因为 Redis 作为一种基于内存的数据库，本身的执行速度就非常快（可以到us级），并发带来收益有限。相反地，并发会带来更多的额外开销，主要包括两个方面：1. 线程切换带来的开销 2. 解决死锁、一致性等问题带来的开销。在这样的 tradeoff 下， Redis 选择了「非必要不并发」。

> 还记得上下文切换会带来哪些开销吗？
> 
> 1. 缓存失效：多个线程是共用 Cache 的，新线程刚上位的时候会发生大量的读缺失，无法利用到缓存。如果切换过于频繁，会直接导致 Cache 的完全失效。这是最主要的开销。
> 2. 资源切换开销：包括内存页表的复制、栈和寄存器的切换、打开文件的切换等等
> 3. 调度开销：线程的切换需要由操作系统进行调度，调度器在计算和调度当中也存在开销。
> 4. 内存开销：这是在线程较多的情况下发生的，OS 维护过多的线程的会也会造成内存占用，进而影响系统的稳定性和性能。

这里有一个问题，在单线程的情况下，Redis 是如何处理网络IO的呢？

### 网络多路复用IO

多路复用IO实现了在一个线程内无阻塞地进行网络IO。

单线程 + 多路复用 是 Redis 快的秘诀。

网络IO的阻塞点在于 Socket 监听的过程，网络多路复用IO的核心观点在于，将网络监听多个 Socket 的过程抽象出来交给了操作系统，而 Redis 只需要一个单线程与操作系统进行交互即可。

Linux 提供了 select/poll/epoll 机制来实现网络多路复用。此处简单介绍一下不同机制的核心思想。

select：

- Socket 以 fd 的形式存在于 Redis 当中，在 select 机制中，Redis 将 fd 从用户态拷贝到内核态（todo：状态切换的过程？），交给操作系统。
- 操作系统遍历 fd 集合，找到发生了网络IO的 Socket，将对应的 fd 集合拷贝回用户态，给 Redis 处理。
- Redis 从 fd 集合当中读取数据并处理。

poll：

- poll 的实现原理和 select 是一样的，两者的区别只在于内核态的 fd 集合容器不同。select 用最大 1024 的 Bitmap，而 poll 使用链表。

epoll：

- epoll 使用了全新的机制，不再需要拷贝和遍历的过程。
- OS 在内核态当中以红黑树的形式存储 fd 集合，Redis 在一开始的时候向内核注册即可。
- epoll 采用了事件驱动的机制，维护了一个事件队列。当 Socket accept时，内核触发事件，将事件加入到事件队列当中。
- Redis 访问事件队列，从队列当中获取 active Socket.

epoll 相比于 select 改进的点在于 1. 节省了两次拷贝 2. 不再需要 O(n) 的轮询，它 O(1) 地从事件队列当中进入、取出。

需要注意的是，尽管多路复用解决了 Socket 阻塞的问题，但是在读写的时候，依然是阻塞的。也就是说，Redis 获得 fd 的过程不阻塞，但是从 Socket fd 里面读取数据的时候依然需要阻塞等待。Linux 并没有提供异步IO的实现机制。

这也导致了真香。随着 Redis 逐渐发现，以上网络IO读写也逐渐限制了 Redis 的性能。因此在 Redis 6.0 当中加入了多线程机制，另外开了几个IO线程负责网络读写。但是注意， 数据处理依然是单线程的。

### 单线程有哪些阻塞点？


## 高性能专题总结

## 持久化

### AOF 

AOF (Append Only File) 是 Redis 提供的一种持久化的方法，主要的作用是记录下 Redis 内所有的写操作。重启复原时只需要读取AOF日志执行一遍即可。

操作系统侧提供了两个系统调用，write() 和 fsync(). write() 将数据写入到内核的缓冲区当中（仍然在内存，因此很快），而 fsync() 则是将缓冲区的数据真正写到磁盘上。

因此，Redis 每次执行命令后都会调用 write ，而对于不同的 fsync 时机，Redis 提供了三种写回策略：

1. Always：每次 write 后，同步地执行 fsync
2. Everysec：每秒执行一次 fsync
3. No：Redis 不执行 fsync，由操作系统调用 fsync （一定时间、buffer 过载等）

#### AOF 重写

由于AOF日志是 Append-Only 的，随着命令执行越来越多，AOF 日志也会越来越臃肿。

> AOF 日志臃肿会带来哪些负面的影响？

因此，Redis 还引入了将AOF日志压缩（或者说 **重写**）的机制。

一个key，被先后 set 为 A/B/C/D/E。可以被压缩为一条命令 set key E；一个队列，先后入A入B出B入C，可以压缩为 enqueue A/C. 这就是AOF重写。

可以看到，AOF重写本质上是结果导向的，因此在重写的时候，需要读取当前 Redis 的内存数据，生成对应的写命令。

AOF重写不应该也没必要阻塞主线程，它是异步执行的。Redis fork 出一个 rewrite 子进程，由子进程负责AOF重写。操作系统在 fork 时采用了 Copy On Write 的技术，fork 时，先复制一份父进程的页表给子进程，此时父子进程的页表是指向同一块内存的，也就是说，在这个过程里面并不会分配新的内存空间给子进程。尽管父子进程共享了内存，但是它们是没有写权限的，一旦某个进程想要写这块内存，就会触发中断，由中断处理程序为进程分配内存并将原内存页当中的内容拷贝到进程的内存页中，然后进程才能进行修改。这就是 Copy On Write。

> COW 应用在哪些场景？
> 
> 1. 操作系统内存分配
> 2. GFS (Google File System) 生成 replica
> 3. Raft Snapshot 生成
>
> 需要注意的是，尽管 COW 尽量地减少了内存占用，但是在写多读少的情况下， 仍然会退化并占用大量的内存。

这也是使用子进程而非线程的原因。线程之间共享内存，会发生并发冲突。

需要注意的是，在子进程重写的时候，父进程可能也在并行地操作 Redis 数据库。此时在重写过程当中的写命令会被记录在 AOF重写缓冲区 当中，重写完成时，重写的AOF文件会与重写缓冲区合并，生成最终的新AOF日志，覆盖原先的AOF日志。

值得注意的是，在重写的时候，父进程依然会写原有的AOF日志，这样即使子进程在重写的时候G了，父进程依然能使用旧的大坨日志，至少不会丢失。因此，在子进程重写的时候，父进程会同时写 AOF缓冲区 和 AOF重写缓冲区。

### RDB 

RDB 是另一种持久化的方法，即生成一个数据库快照。与AOF不同，AOF记录的是写命令，而RDB则直接记录下数据库的KV对。因此，RDB可以用来快速地恢复 Redis 数据，不必再一条条执行命令。

RDB快照的生成与AOF重写有些类似，也是通过子进程 fork + COW 实现的。但是在生成快照时父进程的写操作就没办法记录到快照当中了。也就是说，在快照生成时的修改无法被记录到快照当中，只能等待下一次快照。

解决此问题有两个方法，首先是不 fork 子进程，直接在主线程当中阻塞地生成快照，另一种方法，就是采用 RDB + AOF 的混合模式。

### 混合模式

前面提到，使用子进程生成 RDB 的时候有个问题就是首先按下快门之后，再次按下快门之前的这段时间里面，修改记录是无法被保存的。为了解决这个问题，我们可以采用 RDB + AOF 混合的模式，在两次快门的这段时间里面的写操作记录在 AOF日志 里面，作为RDB的补充。

## 主从复制

Redis 服务器之间可以形成主从架构，类似于 MySQL，实现读写分离的功能，也就是说主库负责写，从库负责读，保持写数据一定是从主库流向从库的。

从库通过命令 `replicaof master_addr port` 成为主库的随从。

这里就产生了一个主从数据同步的疑问：数据是怎么样从主库复制到从库的内？有以下三种不同的方式：

- 全量复制
- 长连接传输
- 增量复制

### 全量复制

全量复制发生于主从初次同步的时候。从库发送一个 `psync ? -1` 给主库，? 表示不知道主库的 id， -1 表示 offset = -1，从头开始复制

随后主库回答自己的 id 和 offset，然后主库 fork 生成自己新的 RDB，通过子进程将生成的 RDB 发送给从库，进行同步。

> fork 生成 RDB 的过程是阻塞的吗？
> 
> No, and yes. 尽管我们提到子进程的存在可以让生成 RDB 的过程异步化，但是 fork 生成子进程本身是阻塞的，例如复制一份页表、复制程序段等。所以整个过程依然存在一定的阻塞。

从库接收到 RDB 之后，清空自己已有的数据（脏数据），然后 apply 从主库传来的数据。



### 长连接传输

初次的全量复制完成之后，主从之间已经基本同步了。此时主从之间会建立一个长连接，通过长连接进行传输少量的命令。



## 哨兵

## 高可靠专题总结

## 缓存

Redis 是基于内存实现的 NoSQL KV数据库，因此常常被用来当作分布式缓存。Redis 提供了优秀的数据结构，满足了缓存中各种不同的需要，但是引入 Redis 作为缓存也会遇到不少问题，本节会详细介绍 Redis 作为缓存的方法以及使用时存在的问题和解决方案。

### 缓存模式

这里强调的是数据更新之后，缓存和数据库也需要对应的更新。

其中有三种更新的模式：

- Cache Aside Pattern
- Read / Write Through Pattern
- Write Behind Pattern

三种模式是逐级递进的。

#### 旁路缓存

旁路缓存将缓存的读和写相关的处理逻辑交给应用层，用脚趾想都知道会造成极大的侵入性和耦合，但是他足够简单。

对于读写请求：

- 读请求：先从缓存找，如果有，直接返回；如果缓存中没有，就从db里面找，找到后填充到缓存当中。
- 写请求：数据库和缓存都需要更新，具体来说，数据库是通过更新，而缓存则是删除（显然任何的更新都会因为并发而产生不一致）。具体的更新、删除策略，会在下一小节 **一致性** 详细提到。

#### 读写穿透

读写穿透是旁路缓存的延伸。

我们注意到旁路缓存虽然简单，但是高侵入高耦合难维护。读写穿透解决了这个问题。

读写穿透将缓存部分的逻辑抽离出来形成一个缓存管理组件（whatever u call），应用层只需要负责发起读和写，具体的读取或者更新逻辑在缓存管理组件内部实现。

读写穿透唯一的坏处是实现比较复杂，尽管这并不是什么大问题。对于稍微复杂一点的项目都可以考虑使用读写穿透，而非旁路缓存。

#### 异步写

Write Behind 是读写穿透的 **异步版本**。

读写穿透当中写依然是同步的，也就是说更新需要等待db完成之后，才会返回结果。

WB 不是这样，数据的读、写都只和缓存打交道。而缓存当中的数据则会定期地返回更新到db当中，这个动作称之为flush。

这种模式的好处在于读写性能非常高，只和缓存有关。但是缺点也很明显，实现复杂（flush），并且一致性极差。

模式|优点|缺点
-|-|-
CAP|实现简单|高耦合、高侵入、难维护
R/WT|低耦合、低侵入、易维护|实现比较复杂
WB|性能非常好，并且降低耦合|实现非常复杂、有丢失数据的风险、并且一致性极差

### 缓存一致性

缓存一致性关注这样一个问题：数据发生更新了，怎么样保证缓存和数据库是一致的？

需要注意的是，任何「更新缓存」都无法保证一致性，只能是删除。

总体来说，有两种策略：

1. 先更新db，后删除缓存。这种方法在很大程度上可以保证一致性，只有一种情况可能出现意外：请求读 -> 请求写 -> 写完删缓存 -> 读完写缓存。但是我们考虑到很少有读比写慢的情况，因此这是可以接受的。
2. 先删缓存，再更新db，再删一次缓存。即 **延迟双删**。第二次删除必须保证在db更新之后过一段时间（读写毕）有了二次删除兜底，就可以把初次删除提到更新之前了。

方法1 一致性的保证比较弱，但是实现简单。方法2 虽然理论上可以保证一致性，但是延时的时机很难把握，而且实现上也比较复杂。

当然，两个方法共有的缺点就是与业务代码超级耦合了，不易维护。并且还有一个问题：删除失败了怎么办？

**解决方案：**

引入消息队列重试。有两个方法：

1. 简单重试：在删除缓存时，如果删除失败了，就把删除消息放到MQ当中，由MQ再次消费。重试则依赖于MQ提供的重试机制（包括死信等）。
2. Binlog 重试：引入 databus 和缓存管理组件，databus 订阅 MySQL 的 binlog，一旦发现有数据更新，触发缓存管理组件当中的回调删除，如果删除失败则放到MQ里面，细节同上。

可以看到，简单重试虽然简单，但是对业务的侵入比较大。

而 binlog 重试通过订阅 binlog 的方式实现了缓存管理与业务的解耦，并且在集群的情况下，可以在集群同步完成后启动删除回调，避免慢随从带来的一致性问题。缺点也很明显，引入中间件，实现复杂而且可用性降低，不稳定。

### 缓存雪崩

缓存雪崩对应的是缓存集体失效从而进攻db的情况，主要有两种可能的场景：

1. 业务层面——大量kv pair集体过期：这可能是因为设置了相同的过期时间，可以通过给过期时间加上一个浮动解决。
2. 系统层面——服务器宕机：可以有以下策略
   1. 使用 Redis 的哨兵和集群，提高可用性
   2. 采用双缓存热备份的方案
   3. 对数据库进限流

#### 双缓存热备份

维护两个缓存集群，互为主备。

在缓存查询的时候，先看主缓存是否可用（未被降级或熔断），再看备缓存，然后才看db。

在缓存更新的时候，通过订阅binlog更新，其中一个缓存删除成功即可。但是任何一个缓存删除失败了都会依赖MQ进行重试。

同时维护一个兜底的定时任务，定期检验主、备、db之间的数据一致性。

注意，为了保证一致性：

- 故障恢复之后，需要更新缓存数据；或者在缓存过期之后再进行缓存切换。
- databus重试+定时任务保证一致性

### 缓存穿透

缓存穿透指的是缓存失效的场景：请求一些缓存当中没有的数据，那么最终请求会打到db之中，然后把脆弱的db打挂，相当于是 **请求直接穿透了缓存层**。这也是一种攻击手段，通过构造不存在的数据去绕过缓存直接攻击db。

解决的思路很简单嘛：把「是否存在于db」的信息构建到缓存层当中，如果在缓存当中发现db当中不存在，直接返回即可。具体来说，有三种实现策略。

1. 非法参数校验：在上层先做一波校验，过滤掉一部分非法的请求。
2. Bloom Filter: 还记得在 **数据结构** 一节当中提到的 Bloom Filter 吗？BF 通过多次哈希将数据分散到 bit 数组的不同位置，从而回答了「是否存在」的问题。当然，由于哈希碰撞的存在，可能会出现误判的情况，因此，BF 只能给出 **NOT contain** / **MIGHT contain** 的回答。尽管如此，BF依然能够以非常小的内在占用拦截住大部分的无效请求。
3. 缓存空对象：使用一些特定的val表示空对象（如“#”），保存到缓存当中。查询时，如果发现val为空对象，则返回null。

BF的优势在于占用内存少，缺点是代码实现比较复杂，并且对于增添/删除不太友好（需要使用布谷鸟哈希等方式解决）。

空对象的优势在于实现简单，并且占用内存、**还有数据不一致的问题**。

### 缓存击穿

缓存穿透是穿透整个缓存存，而缓存击穿则是从一个虚弱点突破缓存，攻击db。这个弱点就是 **hot key**。

当热点key失效时，所有的请求会一瞬间大量打到db里面，形成缓存击穿。

分析以上过程，可以得出缓存击穿的几种解决方案：

1. 互斥锁：通过独占锁的方式，避免所有请求一下子涌入db当中。比较简单的分布式锁实现可以使用SETNX实现自旋锁。分布式锁也有一些更复杂/优化的实现，有空写写。
2. 逻辑过期+非阻塞互斥锁：基于互斥锁改进而来。在原有的过期时间t2之外，还额外设置一个逻辑过期时间t1（t1 < t2）。当读取时，发现到达逻辑过期时间t1，则获取独占锁，将过期时间延长t，到t1+t，然后去db拉取数据更新到缓存中。而在这一过程当中，其他的请求进来发现t1延长之后，就继续使用旧的缓存。
> 方案2的优化点在于缩短了占用阻塞时间。对于方案1来说，阻塞的时间是【请求进入-写回缓存】，而方案2阻塞的时间是【发现过期-完成续约】。一旦完成了t1=t+t1的动作，新进来的请求就可以不抢锁，直接读旧缓存了，不会被阻塞。等到缓存更新丝滑衔接。
3. 懒过期+非阻塞互斥锁：也就是在 Redis 中表现为不过期，自己设置过期时间。等到读的时候，发现他过期了，启动一个异步线程去更新缓存（只需要有一个线程更新即可，因此可以使用非阻塞锁，未获取到说明已经有别的线程在更新了，直接返回即可）

以上的三种方案：

- 方案1的 **优点：** 实现简单，一致性更强；**缺点：** 阻塞时间长，性能变差，压力转移到分布式锁上面，Redis可能顶不住
- 方案2的 **优点：** 同方案1；**缺点：** 实现比较复杂，逻辑过期时间占用一定空间
- 方案3的 **优点：** 速度很快，不需要等待db，不需要重建hot key；**缺点：**复杂，逻辑过期时间占用空间，异步写无法保证一致性。

### HOT key

